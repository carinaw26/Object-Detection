{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f3137e0",
   "metadata": {},
   "source": [
    "# Object Detection Study\n",
    "How to do object detection with pre-trained models for image file, video file and live video.\n",
    "\n",
    "Reference https://www.machinecurve.com/index.php/2021/01/15/object-detection-for-images-and-videos-with-tensorflow-2-x/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20073e89",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "### Python packages\n",
    "```code\n",
    "pip install tensorflow #This will install numpy and related packges\n",
    "pip install opencv-python\n",
    "```\n",
    "### Protoc\n",
    "Download pre-built protoc. For Windows download protoc-3.5.0-win32.zip and unzip it. Add the bin directory to PATH environment variable.\n",
    "\n",
    "https://github.com/protocolbuffers/protobuf/releases/tag/v3.5.0\n",
    "\n",
    "### Object Detection Repository\n",
    "```code\n",
    "git clone https://github.com/tensorflow/models\n",
    "\n",
    "```\n",
    "### Download pre-trained model\n",
    "Download TensorFlow 2 Detection Model from https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md\n",
    "Consider Spped (ms) and COCO (Microsoft Common Object in Context database) mAP (mean Average Precision)\n",
    "For exmample,\n",
    "- CenterNet HourGlass104 512x512 (70 ms 41.9 COCO mAP)\n",
    "- ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8 (39 ms, 28.2 COCO mAP)\n",
    "- EfficientDet D1 640x640 ( 54 ms 38.4 COCO mAP)\n",
    "- Faster R-CNN ResNet101 V1 640x640 (55ms 31.8 mAP)\n",
    "\n",
    "Download the mode and unpack it. You will set the directory to ot_model when create TFObjectDetector instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fb8c80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify model imports\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import platform\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df5db2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disable GPU if necessary\n"
     ]
    }
   ],
   "source": [
    "print (\"Disable GPU if necessary\")\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9a42d4",
   "metadata": {},
   "source": [
    "## Run object detector with live video.\n",
    "Click 'q' to stop. If it can't displace click any key or 'q'. When fail to stop you can manually close the capture window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9137d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run Object Detection ...\n",
      "Detect live viedo ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-02 14:33:40.291553: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    }
   ],
   "source": [
    "# Create object detector\n",
    "class TFObjectDetector():\n",
    "  \n",
    "  # Constructor\n",
    "  def __init__(self, path_to_object_detection = './models/research/object_detection/configs/tf2',\\\n",
    "    path_to_model_checkpoint = './checkpoint', path_to_labels = './labels.pbtxt',\\\n",
    "      model_name = 'ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8'):\n",
    "    self.model_name = model_name\n",
    "    self.pipeline_config_path = path_to_object_detection\n",
    "    self.pipeline_config = os.path.join(f'{self.pipeline_config_path}/{self.model_name}.config')\n",
    "    self.full_config = config_util.get_configs_from_pipeline_file(self.pipeline_config)\n",
    "    self.path_to_model_checkpoint = path_to_model_checkpoint\n",
    "    self.path_to_labels = path_to_labels\n",
    "    self.setup_model()\n",
    "\n",
    "  # Set up model for usage\n",
    "  def setup_model(self):\n",
    "    self.build_model()\n",
    "    self.restore_checkpoint()\n",
    "    self.detection_function = self.get_model_detection_function()\n",
    "    self.prepare_labels()\n",
    "\n",
    "  # Build detection model\n",
    "  def build_model(self):\n",
    "    model_config = self.full_config['model']\n",
    "    assert model_config is not None\n",
    "    self.model = model_builder.build(model_config=model_config, is_training=False)\n",
    "    return self.model\n",
    "\n",
    "  # Restore checkpoint into model\n",
    "  def restore_checkpoint(self):\n",
    "    assert self.model is not None\n",
    "    self.checkpoint = tf.train.Checkpoint(model=self.model)\n",
    "    self.checkpoint.restore(os.path.join(self.path_to_model_checkpoint, 'ckpt-0')).expect_partial()\n",
    "    \n",
    "  # Get a tf.function for detection\n",
    "  def get_model_detection_function(self):\n",
    "    assert self.model is not None\n",
    "    \n",
    "    @tf.function\n",
    "    def detection_function(image):\n",
    "      image, shapes = self.model.preprocess(image)\n",
    "      prediction_dict = self.model.predict(image, shapes)\n",
    "      detections = self.model.postprocess(prediction_dict, shapes)\n",
    "      return detections, prediction_dict, tf.reshape(shapes, [-1])\n",
    "    \n",
    "    return detection_function\n",
    "    \n",
    "  # Prepare labels\n",
    "  # Source: https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/inference_tf2_colab.ipynb\n",
    "  def prepare_labels(self):\n",
    "    label_map = label_map_util.load_labelmap(self.path_to_labels)\n",
    "    categories = label_map_util.convert_label_map_to_categories(\n",
    "        label_map,\n",
    "        max_num_classes=label_map_util.get_max_label_map_index(label_map),\n",
    "        use_display_name=True)\n",
    "    self.category_index = label_map_util.create_category_index(categories)\n",
    "    self.label_map_dict = label_map_util.get_label_map_dict(label_map, use_display_name=True)\n",
    "    \n",
    "  # Get keypoint tuples\n",
    "  # Source: https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/inference_tf2_colab.ipynb\n",
    "  def get_keypoint_tuples(self, eval_config):\n",
    "    tuple_list = []\n",
    "    kp_list = eval_config.keypoint_edge\n",
    "    for edge in kp_list:\n",
    "      tuple_list.append((edge.start, edge.end))\n",
    "    return tuple_list\n",
    "\n",
    "  # Prepare image\n",
    "  def prepare_image(self, image):\n",
    "    return tf.convert_to_tensor(\n",
    "      np.expand_dims(image, 0), dtype=tf.float32\n",
    "    )\n",
    "    \n",
    "  # Perform detection\n",
    "  def detect(self, image, label_offset = 1):\n",
    "    # Ensure that we have a detection function\n",
    "    assert self.detection_function is not None\n",
    "    \n",
    "    # Prepare image and perform prediction\n",
    "    image = image.copy()\n",
    "    image_tensor = self.prepare_image(image)\n",
    "    detections, predictions_dict, shapes = self.detection_function(image_tensor)\n",
    "\n",
    "    # Use keypoints if provided\n",
    "    keypoints, keypoint_scores = None, None\n",
    "    if 'detection_keypoints' in detections:\n",
    "      keypoints = detections['detection_keypoints'][0].numpy()\n",
    "      keypoint_scores = detections['detection_keypoint_scores'][0].numpy()\n",
    "    \n",
    "    # Perform visualization on output image/frame \n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "      image,\n",
    "      detections['detection_boxes'][0].numpy(),\n",
    "      (detections['detection_classes'][0].numpy() + label_offset).astype(int),\n",
    "      detections['detection_scores'][0].numpy(),\n",
    "      self.category_index,\n",
    "      use_normalized_coordinates=True,\n",
    "      max_boxes_to_draw=25,\n",
    "      min_score_thresh=.40,\n",
    "      agnostic_mode=False,\n",
    "      keypoints=keypoints,\n",
    "      keypoint_scores=keypoint_scores,\n",
    "      keypoint_edges=self.get_keypoint_tuples(self.full_config['eval_config']))\n",
    "    \n",
    "    # Return the image\n",
    "    return image\n",
    "\n",
    "  # Predict image from folder\n",
    "  def detect_image(self, path, output_path):\n",
    "\n",
    "    # Load image\n",
    "    image = cv2.imread(path)\n",
    "\n",
    "    # Perform object detection and add to output file\n",
    "    output_file = self.detect(image)\n",
    "    \n",
    "    # Write output file to system\n",
    "    cv2.imwrite(output_path, output_file)\n",
    "    \n",
    "  # Predict video from folder\n",
    "  def detect_video(self, path, output_path):\n",
    "    \n",
    "    # Set output video writer with codec\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, 29.97, (640, 360))\n",
    "    \n",
    "    # Read the video\n",
    "    vidcap = cv2.VideoCapture(path)\n",
    "    frame_read, image = vidcap.read()\n",
    "    count = 0\n",
    "    \n",
    "    # Iterate over frames and pass each for prediction\n",
    "    while frame_read:\n",
    "      print(f\"process {count}\")\n",
    "      # Perform object detection and add to output file\n",
    "      output_file = self.detect(image)\n",
    "      \n",
    "      # Write frame with predictions to video\n",
    "      out.write(output_file)\n",
    "      print(f\"done process {count}\")\n",
    "      # Read next frame\n",
    "      frame_read, image = vidcap.read()\n",
    "      count += 1\n",
    "        \n",
    "    # Release video file when we're ready\n",
    "    out.release()\n",
    "    print(\"Done\")\n",
    "    \n",
    "  # Predict video from capture\n",
    "  def detect_live_video(self):\n",
    "    # define a video capture object\n",
    "    cv2.namedWindow('frame')\n",
    "    video_index = 0\n",
    "    if platform.system() == 'Darwin':\n",
    "        video_index = 1\n",
    "    vid = cv2.VideoCapture(video_index)\n",
    "  \n",
    "    while(True): \n",
    "      # Capture the video frame\n",
    "      # by frame\n",
    "      ret, frame = vid.read()\n",
    "\n",
    "      # Perform object detection\n",
    "      frame_out = self.detect(frame)\n",
    "      # Display the resulting frame\n",
    "      cv2.imshow('frame', frame_out)\n",
    "      \n",
    "      # the 'q' button is set as the\n",
    "      # quitting button you may use any\n",
    "      # desired button of your choice\n",
    "      if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break  \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "  ot_model = \"ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8\"\n",
    "  print(\"Run Object Detection ...\")\n",
    "  detector = TFObjectDetector('./Tensorflow/models/research/object_detection/configs/tf2', \n",
    "        './Tensorflow/workspace/pre-trained-models/' + ot_model + '/checkpoint', \n",
    "        './Tensorflow/models/research/object_detection/data/mscoco_label_map.pbtxt', \n",
    "        ot_model)\n",
    "  #print(\"Detect still image ...\")\n",
    "  #detector.detect_image('c:/tmp/beach.png', 'c:/tmp/beachout.png')\n",
    "  #print(\"Detect viedo ...\")\n",
    "  #detector.detect_video('c:/tmp/AHD_30s_SD360P.mp4', 'c:/tmp/AHD_30s_SD360P_out.mp4')\n",
    "\n",
    "  print(\"Detect live viedo ...\")\n",
    "  detector.detect_live_video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d84343",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7db896",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
